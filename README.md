# NLP - Natural Language Processing
## In this repository you will find my work in several different problems related to NLP. It is organized in the following way. 
* Assignment1/Part 2 - Language Models: The objetive is to train different language models for different languages (English, France, German) and then, given a test set, use them to assign a probability of the setences belonging to a particular model. 
  * Letter language model
  * Bigram model with Add One Smoothing 
  * Bigram model with Good Touring Smoothing
  * Trigram model with Add One Smoothing
* Assigment2 - Part Of Speeach Tagging: Different implementations of decoding algorithms trained in a subset of the Brown corpus.  
  * a) - Majority class
  * b) - Majority class enhanced with some transformation rules
  * c) - Hidden Markov Model (Viterbi Algorithm): supervised training using an annotated corpus and the Viterbi HMM to encoding. 
  * d) - Viterbi with Beam Search
* Final Project - A complete Python project to predict binary sentiment of Twitter corpus using word embeddings as features. 

